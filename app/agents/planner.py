from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from typing import List, Dict, Any
from app.config import Config
import json
import logging

def generate_plan(specification: str) -> List[str]:
    """Gera um plano de TDD (lista de sub-requisitos) a partir da especifica√ß√£o."""
    llm = ChatOpenAI(model=Config.MODEL, temperature=0.1)
    
    messages = [
        SystemMessage(content=(
            "Voc√™ √© o Planejador (Planner), um especialista em Test Driven Development (TDD). "
            "Sua fun√ß√£o √© receber um requisito de alto n√≠vel e dividi-lo em um plano de TDD passo a passo. "
            "Cada passo representa um pequeno sub-requisito incremental e segue o ciclo cl√°ssico do TDD: "
            "\n1. O Tester escreve o pr√≥ximo teste mais simples para o sub-requisito. "
            "\n2. O Developer implementa o c√≥digo m√≠nimo necess√°rio para passar no teste. "
            "\n3. O Executor executa todos os testes. "
            "\n4. Se os testes passarem, o Reviewer analisa o c√≥digo. "
            "\n5. Repita para o pr√≥ximo sub-requisito."
            "\n\nREGRAS DE FORMATA√á√ÉO:"
            "\n1. Retorne **apenas** um JSON v√°lido. N√£o inclua nenhuma explica√ß√£o ou texto fora do JSON."
            "\n2. O JSON deve conter a chave 'tdd_plan' com uma lista de etapas (objetos JSON)."
            "\n3. Cada etapa deve conter:"
            "\n   - 'sub_requirement': descri√ß√£o curta e espec√≠fica do objetivo do teste (ex: 'Testar soma de n√∫meros positivos')."
            "\n   - 'actions': lista com as instru√ß√µes para Tester, Developer, Executor e Reviewer, seguindo o ciclo TDD."
            "\n\nFormato esperado:"
            "\n{\n  'tdd_plan': [\n    {\n      'sub_requirement': '...',\n      'actions': [\n        'Tester: ...',\n        'Developer: ...',\n        'Executor: ...',\n        'Reviewer: ...'\n      ]\n    }\n  ]\n}"
        )),
        HumanMessage(content=(
            f"üìù Requisito Principal:\n{specification}\n\n"
            "Gere o plano de TDD detalhado e sequencial para este requisito."
        ))
    ]

    response = llm.invoke(messages)
    content = response.content.strip()
    
    try:
        # Tenta corrigir a resposta se o LLM incluiu markdown
        if content.startswith('```json'):
            content = content.strip('```json').strip()
        elif content.startswith('```'):
            content = content.strip('```').strip()
            
        data = json.loads(content)
        
        # FIX: Usar a chave correta 'tdd_plan' conforme especificado no prompt
        tdd_plan = data.get('tdd_plan', [])
        
        # Extrair apenas os 'sub_requirement' de cada etapa
        sub_requirements = [step['sub_requirement'] for step in tdd_plan if 'sub_requirement' in step]
        
        return sub_requirements
        
    except (json.JSONDecodeError, KeyError, TypeError) as e:
        logging.error(f"‚ùå Erro ao decodificar JSON do Planner: {e}")
        logging.error(f"Conte√∫do do LLM: {content}")
        # Retorna um plano de falha se houver erro
        return ["Falha ao gerar o plano, escreva um teste que valide a falha de implementa√ß√£o."]